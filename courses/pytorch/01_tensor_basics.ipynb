{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.1304e+12, 3.0763e-41, 1.8784e+12],\n",
      "         [3.0763e-41, 1.1210e-43, 0.0000e+00]],\n",
      "\n",
      "        [[8.9683e-44, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 2.1299e+12, 3.0763e-41]]])\n",
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(2)\n",
    "x = torch.empty(2, 2, 3)\n",
    "print(x) # values are uninitialised\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1076, 0.6804],\n",
       "        [0.5216, 0.6133]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(2, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2) # float32\n",
    "x = torch.ones(2, 2, dtype=torch.int)\n",
    "x = torch.ones(2, 2, dtype=torch.double) # float64\n",
    "x = torch.ones(2, 2, dtype=torch.float16)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5000, 0.1000])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create from list\n",
    "x = torch.tensor([2.5, 0.1])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5485, 0.0863],\n",
      "        [0.6505, 0.0135]])\n",
      "tensor([[0.2063, 0.6991],\n",
      "        [0.6515, 0.7297]])\n",
      "tensor([[0.7547, 0.7855],\n",
      "        [1.3020, 0.7433]])\n",
      "tensor([[0.7547, 0.7855],\n",
      "        [1.3020, 0.7433]])\n",
      "tensor([[0.7547, 0.7855],\n",
      "        [1.3020, 0.7433]])\n",
      "tensor([[-0.2063, -0.6991],\n",
      "        [-0.6515, -0.7297]])\n",
      "tensor([[0.4139, 0.0678],\n",
      "        [0.8470, 0.0101]])\n",
      "tensor([[0.7267, 0.1099],\n",
      "        [0.4996, 0.0182]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 2)\n",
    "y = torch.rand(2, 2)\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "z = x + y # eltwise\n",
    "print(z)\n",
    "\n",
    "z = torch.add(x, y) # also eltwise\n",
    "print(z)\n",
    "\n",
    "y.add_(x) # functions with trailing underscores work in place\n",
    "print(y)\n",
    "\n",
    "z = x - y # torch.sub(x, y), y.sub_(x)\n",
    "print(z)\n",
    "\n",
    "z = x * y # torch.mul(x, y), y.mul_(x)\n",
    "print(z)\n",
    "\n",
    "z = x  / y # torch.div(x, y), y.div_(x)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0855, 0.7053, 0.3198],\n",
      "        [0.9366, 0.6046, 0.6927],\n",
      "        [0.3896, 0.9030, 0.0279],\n",
      "        [0.8220, 0.2443, 0.5046],\n",
      "        [0.4608, 0.0803, 0.5712]])\n",
      "tensor([0.0855, 0.9366, 0.3896, 0.8220, 0.4608])\n",
      "tensor([0.9366, 0.6046, 0.6927])\n",
      "tensor(0.6046)\n",
      "0.6045728921890259\n"
     ]
    }
   ],
   "source": [
    "# Slicing\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "print(x[:, 0]) # all rows for column 0\n",
    "print(x[1, :]) # all cols for 2nd row\n",
    "print(x[1,1])\n",
    "print(x[1,1].item())  # tensors with 1 element have a .item() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2703, 0.1382, 0.3164, 0.2121],\n",
      "        [0.7946, 0.6832, 0.9260, 0.8544],\n",
      "        [0.9761, 0.8947, 0.2375, 0.3727],\n",
      "        [0.2394, 0.7658, 0.4770, 0.5699]])\n",
      "tensor([0.2703, 0.1382, 0.3164, 0.2121, 0.7946, 0.6832, 0.9260, 0.8544, 0.9761,\n",
      "        0.8947, 0.2375, 0.3727, 0.2394, 0.7658, 0.4770, 0.5699])\n",
      "torch.Size([16])\n",
      "torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# Reshaping\n",
    "x = torch.rand(4, 4)\n",
    "print(x)\n",
    "\n",
    "y = x.view(16) # 1d\n",
    "print(y)\n",
    "print(y.size())\n",
    "\n",
    "y = x.view(-1, 8) # -1 means infer the size\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# To / from numpy\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "\n",
    "b = a.numpy() # is a view to the same memory as a when on CPU\n",
    "print(type(b))\n",
    "\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "\n",
    "a = np.ones(5)\n",
    "print(a)\n",
    "b = torch.from_numpy(a) # also a view to same memory, float64 by default\n",
    "print(b)\n",
    "\n",
    "a +=1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/craigc/miniconda3/envs/obb/lib/python3.9/site-packages/torch/cuda/__init__.py:145: UserWarning: \n",
      "NVIDIA GeForce RTX 3080 Ti with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA GeForce RTX 3080 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [54], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m      3\u001b[0m     device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mones(\u001b[39m5\u001b[39;49m, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m      5\u001b[0m     y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(\u001b[39m5\u001b[39m)\n\u001b[1;32m      6\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# CUDA\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    x = torch.ones(5, device=device)\n",
    "    y = torch.ones(5)\n",
    "    y = y.to(device=device)\n",
    "\n",
    "    z = x + y\n",
    "\n",
    "    # z.numpy() # won't work, need to move it back to the CPU first\n",
    "    z = z.to('cpu')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88062a28fc62843222afb273016058ec29bdaaf682f97667a8dc943e55996fd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
